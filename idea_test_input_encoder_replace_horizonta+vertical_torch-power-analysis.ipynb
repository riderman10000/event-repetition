{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### testing out the encoder replacement in this section and see if it works or not\n",
    "\n",
    "##### testing by adding the horizontal and vertical sections together \n",
    "\n",
    "##### the inference speed and model size decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2 \n",
    "import argparse\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from repnet import utils, plots\n",
    "from repnet.model import RepNet\n",
    "\n",
    "import event_tools.tools as tl \n",
    "import visualization as vz\n",
    "import event_tools.e2v as e2v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_class = \"class5\"\n",
    "# event_user = \"user02_fluorescent\"\n",
    "event_user = \"user02_fluorescent_led\"\n",
    "# event_user = \"user02_lab\"\n",
    "# event_user = \"user02_led\"\n",
    "# event_user = \"user02_natural\"\n",
    "\n",
    "event_csv_file_name = f\"./event_csv/split_data/{event_class}/{event_user}.csv\"\n",
    "\n",
    "count_data = {\n",
    "    \"class\": event_class,\n",
    "    \"condition\": event_user,\n",
    "    \"count\": 0,\n",
    "}\n",
    "\n",
    "# output count info \n",
    "out_csv_file = \"encoder_replaced_output.csv\"\n",
    "\n",
    "if os.path.exists(out_csv_file):\n",
    "    try: \n",
    "        out_df = pd.read_csv(out_csv_file)\n",
    "    except: \n",
    "        out_df = pd.DataFrame([count_data])\n",
    "else: \n",
    "    with open(out_csv_file, \"w\") as f:\n",
    "        f.write(\"class,condition,count\\n\")\n",
    "    out_df = pd.read_csv(out_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>condition</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class               condition  count\n",
       "0   class2  user02_fluorescent_led     10\n",
       "1   class2      user02_fluorescent     14\n",
       "2   class2              user02_lab      9\n",
       "3   class2              user02_led      9\n",
       "4   class2          user02_natural     16\n",
       "5   class3  user02_fluorescent_led     12\n",
       "6   class3      user02_fluorescent     11\n",
       "7   class3              user02_lab     10\n",
       "8   class3              user02_led     12\n",
       "9   class3          user02_natural     11\n",
       "10  class4  user02_fluorescent_led      8\n",
       "11  class4      user02_fluorescent      9\n",
       "12  class4              user02_lab      9\n",
       "13  class4              user02_led      7\n",
       "14  class4          user02_natural     10\n",
       "15  class5  user02_fluorescent_led      6\n",
       "16  class5      user02_fluorescent      9\n",
       "17  class5              user02_lab      8\n",
       "18  class5              user02_led      6\n",
       "19  class5          user02_natural      8\n",
       "20  class6  user02_fluorescent_led      6\n",
       "21  class6      user02_fluorescent      9\n",
       "22  class6              user02_lab      9\n",
       "23  class6              user02_led      9\n",
       "24  class6          user02_natural      8\n",
       "25  class7  user02_fluorescent_led      7\n",
       "26  class7      user02_fluorescent      5\n",
       "27  class7              user02_lab      9\n",
       "28  class7              user02_led      6\n",
       "29  class7          user02_natural      8\n",
       "30  class5  user02_fluorescent_led      4\n",
       "31  class5  user02_fluorescent_led      6\n",
       "32  class5  user02_fluorescent_led      6\n",
       "33  class5      user02_fluorescent      6\n",
       "34  class5      user02_fluorescent      6\n",
       "35  class6      user02_fluorescent      3\n",
       "36  class3      user02_fluorescent     11\n",
       "37  class5      user02_fluorescent      6\n",
       "38  class5      user02_fluorescent      6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out_df = pd.concat([out_df, pd.DataFrame(columns=[\"class\", \"condition\", \"count\"])])\n",
    "\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = './'\n",
    "events = tl.load_event_data(\n",
    "    # './event_csv/split_data/class7/user02_lab.csv')  # Replace with your actual file path\n",
    "    event_csv_file_name) # Replace with your actual file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repnet model variables \n",
    "weights = './pytorch_weights.pth'\n",
    "device = 'cuda'\n",
    "strides = [1, 2, 3, 4 , 8]\n",
    "\n",
    "\n",
    "OUT_VISUALIZATIONS_DIR = './visualization/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spiking variables\n",
    "\n",
    "width=128\n",
    "height=128\n",
    "\n",
    "horizontal_member_potential = np.zeros(width) \n",
    "vertical_member_potential = np.zeros(width) \n",
    "\n",
    "horizontal_neurons = np.zeros(width).reshape((1, -1))\n",
    "vertical_neurons = np.zeros(height).reshape((1, -1))\n",
    "\n",
    "# horizontal_member_potential = torch.zeros((6, width), device=device) \n",
    "# vertical_member_potential = torch.zeros((64, width), device=device) \n",
    "\n",
    "# horizontal_neurons = torch.zeros((64, width), device=device).reshape((1, -1))\n",
    "# vertical_neurons = torch.zeros((64, height), device=device).reshape((1, -1))\n",
    "\n",
    "\n",
    "\n",
    "decay = .009 # 0.009\n",
    "batch_size = 1 #  64 #  \n",
    "random_wt_2d = lambda _row, _col: torch.ones((_row, _col), device=device) * 0.5 # np.round(np.random.rand(_row, _col), 3)\n",
    "weight_input_horizontal_hidden = random_wt_2d(batch_size, height) # np.ones((1, height)) * weight_scale_1\n",
    "weight_input_horizontal_hidden_1 = random_wt_2d(height, height//2) # np.ones((height, height//2)) * weight_scale_1\n",
    "\n",
    "# not considering the height and width for the image as they are symmetrical \n",
    "weight_input_vertical_hidden = random_wt_2d(batch_size, height) # np.ones((1, height)) * weight_scale_1\n",
    "weight_input_vertical_hidden_1 = random_wt_2d(height, height//2) # np.ones((height, height//2)) * weight_scale_1\n",
    "\n",
    "\n",
    "\n",
    "peak = 255 \n",
    "spike = 1 # 255 \n",
    "threshold = 0.8 \n",
    "\n",
    "fps = 60\n",
    "frame_per_second  = 1/fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e2v.save_event_as_video(events,name=\"event.mp4\", frame_per_second=frame_per_second, decay=0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read frames and apply preprocessing \n",
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((112, 112)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=0.5, std=0.5),      \n",
    "])\n",
    "\n",
    "raw_frames, frames = [], [] \n",
    "\n",
    "for idx, frame_image in enumerate(\n",
    "    e2v.get_event_frame(events, frame_per_second = frame_per_second, \n",
    "        decay= decay)):\n",
    "    cv2.imshow('raw' , frame_image)\n",
    "    frame_image = frame_image #.T\n",
    "    frames.append(torch.from_numpy(frame_image).float().to(device))\n",
    "    \n",
    "    frame_image = np.clip(frame_image * 255, 0, 255).astype(np.uint8)\n",
    "    frame_image = cv2.cvtColor(frame_image, cv2.COLOR_GRAY2BGR)\n",
    "    cv2.imshow('test', cv2.resize(frame_image, [frame_image.shape[0] * 10, frame_image.shape[0] * 10] )) \n",
    "    \n",
    "    if(cv2.waitKey(1) == ord('q')):\n",
    "        break \n",
    "    raw_frames.append(frame_image)\n",
    "    # frame = transform(frame_image)\n",
    "    # frames.append(frame)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(326, 326, list)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_frames), len(frames), type(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/rlwagun/.cache/torch/hub/huggingface_pytorch-image-models_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RepNet(\n",
       "  (temporal_conv): Sequential(\n",
       "    (0): Conv3d(1024, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(3, 1, 1), dilation=(3, 1, 1))\n",
       "    (1): BatchNorm3d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveMaxPool3d(output_size=(None, 1, 1))\n",
       "    (4): Flatten(start_dim=2, end_dim=4)\n",
       "  )\n",
       "  (tsm_conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (period_length_head): Sequential(\n",
       "    (0): TranformerLayer(\n",
       "      (input_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=512, out_features=32, bias=True)\n",
       "  )\n",
       "  (periodicity_head): Sequential(\n",
       "    (0): TranformerLayer(\n",
       "      (input_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "model = RepNet()\n",
    "state_dict = torch.load(weights)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "if hasattr(model, 'encoder'):\n",
    "    del model.encoder\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage: 98.57 MB\n",
      "CPU RAM Usage: 850.85 MB\n",
      "Model Size: 78.13 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "# GPU Memory Usage\n",
    "gpu_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # Convert to MB\n",
    "print(f\"GPU Memory Usage: {gpu_memory:.2f} MB\")\n",
    "\n",
    "# CPU RAM Usage\n",
    "ram_usage = psutil.Process().memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "print(f\"CPU RAM Usage: {ram_usage:.2f} MB\")\n",
    "\n",
    "def get_model_size(model):\n",
    "    param_size = sum(p.numel() * p.element_size() for p in model.parameters())  # Model parameters\n",
    "    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())  # Model buffers (like BatchNorm stats)\n",
    "    total_size_mb = (param_size + buffer_size) / (1024 * 1024)  # Convert to MB\n",
    "    return total_size_mb\n",
    "\n",
    "model_size = get_model_size(model)\n",
    "print(f\"Model Size: {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frames = torch.stack(frames)\n",
    "len(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading Jetson power: Command '['tegrastats']' timed out after 1 seconds\n",
      "Power draw (W): 0.0\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "\n",
    "def get_jetson_power_snapshot():\n",
    "    \"\"\"Returns Jetson average power usage (Watts) from tegrastats.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['tegrastats'], stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, timeout=1)\n",
    "        output = result.stdout.decode()\n",
    "\n",
    "        # Look for VDD_IN or other power fields\n",
    "        match = re.search(r'VDD_IN (\\d+)mW', output)\n",
    "        if match:\n",
    "            return int(match.group(1)) / 1000  # Convert mW to W\n",
    "\n",
    "        print(\"Could not find VDD_IN in tegrastats output.\")\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        print(\"Error reading Jetson power:\", e)\n",
    "        return 0.0\n",
    "# Example usage\n",
    "print(\"Power draw (W):\", get_jetson_power_snapshot())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "352 ms ± 12 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "import torch\n",
    "\n",
    "# Initialize potentials\n",
    "horizontal_member_potential = torch.zeros((1, width), device=device)\n",
    "vertical_member_potential = torch.zeros((1, width), device=device)\n",
    "\n",
    "best_stride, best_confidence, best_period_length, best_period_count, best_periodicity_score, best_embeddings = None, None, None, None, None, None\n",
    "\n",
    "spikes_collection = []\n",
    "# Process frames sequentially while optimizing computations\n",
    "# for idx in range(frames.shape[0]):  # Stride-based loop\n",
    "for idx in range(len(frames)):  # Stride-based loop\n",
    "    frame_image = frames[idx]\n",
    "\n",
    "    # Update potentials sequentially\n",
    "    horizontal_member_potential.mul_(decay).add_(weight_input_horizontal_hidden @ frame_image)\n",
    "    vertical_member_potential.mul_(decay).add_(weight_input_vertical_hidden @ frame_image.T)\n",
    "\n",
    "    # Generate spikes\n",
    "    spike_mask_h = horizontal_member_potential > (spike * threshold)\n",
    "    spike_mask_v = vertical_member_potential > (spike * threshold)\n",
    "\n",
    "    horizontal_neurons = spike_mask_h.float()\n",
    "    vertical_neurons = spike_mask_v.float()\n",
    "\n",
    "    horizontal_member_potential.masked_fill_(spike_mask_h, 0).relu_()\n",
    "    vertical_member_potential.masked_fill_(spike_mask_v, 0).relu_()\n",
    "\n",
    "    # Collect spikes\n",
    "    spikes_collection.append(torch.cat([horizontal_neurons, vertical_neurons], dim=-1))\n",
    "\n",
    "\n",
    "for stride in strides:\n",
    "    # apply stride \n",
    "    stride_frames = spikes_collection[::stride]\n",
    "    stride_frames = stride_frames[:(len(stride_frames) // 64) * 64]\n",
    "    if len(stride_frames) < 64:\n",
    "        continue # Skip this stride if there are not enough frames \n",
    "        \n",
    "    raw_period_length, raw_periodicity_score, embeddings = [], [], []\n",
    "\n",
    "    # # Process batch inference every 64 frames\n",
    "    # if len(stride_frames) == 64:\n",
    "    with torch.no_grad():\n",
    "        spikes_0 = torch.stack(stride_frames).view(-1, 64, 128 * 2).to(device)\n",
    "        batch_period_length, batch_periodicity, batch_embeddings = model(spikes_0)\n",
    "\n",
    "        # Store results\n",
    "        raw_period_length.append(batch_period_length[0].cpu())\n",
    "        raw_periodicity_score.append(batch_periodicity[0].cpu())\n",
    "        embeddings.append(batch_embeddings[0].cpu())\n",
    "\n",
    "    # Post-process results\n",
    "    if raw_period_length and raw_periodicity_score:\n",
    "        raw_period_length, raw_periodicity_score, embeddings = map(torch.cat, [raw_period_length, raw_periodicity_score, embeddings])\n",
    "        confidence, period_length, period_count, periodicity_score = model.get_counts(raw_period_length, raw_periodicity_score, stride)\n",
    "\n",
    "        if best_confidence is None or confidence > best_confidence:\n",
    "            best_stride, best_confidence, best_period_length, best_period_count, best_periodicity_score, best_embeddings = stride, confidence, period_length, period_count, periodicity_score, embeddings\n",
    "\n",
    "# Final check\n",
    "if best_stride is None:\n",
    "    raise RuntimeError('Stride values too large; no 64-frame chunk could be sampled. Try different --strides values.')\n",
    "\n",
    "print(f'Predicted period length: {best_period_length/fps:.1f} sec (~{int(best_period_length)} frames) with confidence {best_confidence:.2f}, using a stride of {best_stride}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Initialize potentials\n",
    "    horizontal_member_potential = torch.zeros((1, width), device=device)\n",
    "    vertical_member_potential = torch.zeros((1, width), device=device)\n",
    "\n",
    "    best_stride, best_confidence, best_period_length, best_period_count, best_periodicity_score, best_embeddings = None, None, None, None, None, None\n",
    "\n",
    "    spikes_collection = []\n",
    "    # Process frames sequentially while optimizing computations\n",
    "    # for idx in range(frames.shape[0]):  # Stride-based loop\n",
    "    for idx in range(len(frames)):  # Stride-based loop\n",
    "        frame_image = frames[idx]\n",
    "\n",
    "        # Update potentials sequentially\n",
    "        horizontal_member_potential.mul_(decay).add_(weight_input_horizontal_hidden @ frame_image)\n",
    "        vertical_member_potential.mul_(decay).add_(weight_input_vertical_hidden @ frame_image.T)\n",
    "\n",
    "        # Generate spikes\n",
    "        spike_mask_h = horizontal_member_potential > (spike * threshold)\n",
    "        spike_mask_v = vertical_member_potential > (spike * threshold)\n",
    "\n",
    "        horizontal_neurons = spike_mask_h.float()\n",
    "        vertical_neurons = spike_mask_v.float()\n",
    "\n",
    "        horizontal_member_potential.masked_fill_(spike_mask_h, 0).relu_()\n",
    "        vertical_member_potential.masked_fill_(spike_mask_v, 0).relu_()\n",
    "\n",
    "        # Collect spikes\n",
    "        spikes_collection.append(torch.cat([horizontal_neurons, vertical_neurons], dim=-1))\n",
    "\n",
    "\n",
    "    for stride in strides:\n",
    "        # apply stride \n",
    "        stride_frames = spikes_collection[::stride]\n",
    "        stride_frames = stride_frames[:(len(stride_frames) // 64) * 64]\n",
    "        if len(stride_frames) < 64:\n",
    "            continue # Skip this stride if there are not enough frames \n",
    "            \n",
    "        raw_period_length, raw_periodicity_score, embeddings = [], [], []\n",
    "\n",
    "        # # Process batch inference every 64 frames\n",
    "        # if len(stride_frames) == 64:\n",
    "        with torch.no_grad():\n",
    "            spikes_0 = torch.stack(stride_frames).view(-1, 64, 128 * 2).to(device)\n",
    "            batch_period_length, batch_periodicity, batch_embeddings = model(spikes_0)\n",
    "\n",
    "            # Store results\n",
    "            raw_period_length.append(batch_period_length[0].cpu())\n",
    "            raw_periodicity_score.append(batch_periodicity[0].cpu())\n",
    "            embeddings.append(batch_embeddings[0].cpu())\n",
    "\n",
    "        # Post-process results\n",
    "        if raw_period_length and raw_periodicity_score:\n",
    "            raw_period_length, raw_periodicity_score, embeddings = map(torch.cat, [raw_period_length, raw_periodicity_score, embeddings])\n",
    "            confidence, period_length, period_count, periodicity_score = model.get_counts(raw_period_length, raw_periodicity_score, stride)\n",
    "\n",
    "            if best_confidence is None or confidence > best_confidence:\n",
    "                best_stride, best_confidence, best_period_length, best_period_count, best_periodicity_score, best_embeddings = stride, confidence, period_length, period_count, periodicity_score, embeddings\n",
    "\n",
    "    # Final check\n",
    "    if best_stride is None:\n",
    "        raise RuntimeError('Stride values too large; no 64-frame chunk could be sampled. Try different --strides values.')\n",
    "\n",
    "    print(f'Predicted period length: {best_period_length/fps:.1f} sec (~{int(best_period_length)} frames) with confidence {best_confidence:.2f}, using a stride of {best_stride}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Predicted period length: 0.8 sec (~45 frames) with confidence 0.98, using a stride of 2.\n",
      "Avg Inference Time: 364.19 ms\n",
      "Avg Power: 6.37 W\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from jtop import jtop\n",
    "\n",
    "num_samples=20\n",
    "interval=0.05\n",
    "power_samples = []\n",
    "inference_times = []\n",
    "\n",
    "with jtop() as jetson:\n",
    "    if not jetson.ok():\n",
    "        print(\"Jetson is not ready.\")\n",
    "        # return {}\n",
    "\n",
    "    # Wait for sensors to stabilize\n",
    "    time.sleep(1)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if not jetson.ok():\n",
    "            break\n",
    "\n",
    "        # Run inference and measure time\n",
    "        t0 = time.time()\n",
    "        result = run()\n",
    "        t1 = time.time()\n",
    "\n",
    "        inference_time_ms = (t1 - t0) * 1000  # convert to milliseconds\n",
    "        inference_times.append(inference_time_ms)\n",
    "\n",
    "        try:\n",
    "            power = jetson.power['tot']['power'] / 1000.0  # mW to W\n",
    "            power_samples.append(power)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        time.sleep(interval)\n",
    "\n",
    "avg_inference_time_ms = sum(inference_times) / len(inference_times)\n",
    "avg_power = sum(power_samples) / len(power_samples) if power_samples else 0\n",
    "\n",
    "print(f\"Avg Inference Time: {avg_inference_time_ms:.2f} ms\")\n",
    "print(f\"Avg Power: {avg_power:.2f} W\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Trial 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 71\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvg Energy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_energy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m J\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# # Replace this with your actual inference method\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# def run():\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#     # Example workload (simulate inference)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Run the test\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[43mrun_inference_with_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 31\u001b[0m, in \u001b[0;36mrun_inference_with_metrics\u001b[0;34m(run_fn, num_trials)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Get pre-inference power\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m power_before \u001b[38;5;241m=\u001b[39m \u001b[43mget_jetson_power_snapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Time the inference\u001b[39;00m\n\u001b[1;32m     34\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[0;32mIn[25], line 8\u001b[0m, in \u001b[0;36mget_jetson_power_snapshot\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns Jetson average power usage (Watts) from tegrastats.\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtegrastats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#, timeout=1)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     output \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Look for VDD_IN or other power fields\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1141\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout:\n\u001b[0;32m-> 1141\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "def get_jetson_power_snapshot():\n",
    "    \"\"\"Returns Jetson average power usage (Watts) from tegrastats.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(['tegrastats'], stdout=subprocess.PIPE, stderr=subprocess.DEVNULL) #, timeout=1)\n",
    "        output = result.stdout.decode()\n",
    "\n",
    "        # Look for VDD_IN or other power fields\n",
    "        match = re.search(r'VDD_IN (\\d+)mW', output)\n",
    "        if match:\n",
    "            return int(match.group(1)) / 1000  # Convert mW to W\n",
    "\n",
    "        print(\"Could not find VDD_IN in tegrastats output.\")\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        print(\"Error reading Jetson power:\", e)\n",
    "        return 0.0\n",
    "    \n",
    "def run_inference_with_metrics(run_fn, num_trials=5):\n",
    "    \"\"\"Runs inference and logs average time, power, and estimated energy.\"\"\"\n",
    "    total_time = 0.0\n",
    "    total_power = 0.0\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        print(f\"\\n[Trial {i+1}]\")\n",
    "\n",
    "        # Get pre-inference power\n",
    "        power_before = get_jetson_power_snapshot()\n",
    "\n",
    "        # Time the inference\n",
    "        start = time.time()\n",
    "        run_fn()  # Your actual inference method\n",
    "        end = time.time()\n",
    "\n",
    "        # Get post-inference power\n",
    "        power_after = get_jetson_power_snapshot()\n",
    "\n",
    "        elapsed = end - start\n",
    "        avg_power = (power_before + power_after) / 2\n",
    "        energy = avg_power * elapsed\n",
    "\n",
    "        print(f\"Inference Time: {elapsed:.4f} sec\")\n",
    "        print(f\"Avg Power: {avg_power:.4f} W\")\n",
    "        print(f\"Estimated Energy: {energy:.4f} J\")\n",
    "\n",
    "        total_time += elapsed\n",
    "        total_power += avg_power\n",
    "\n",
    "    print(\"\\n=== Overall Averages ===\")\n",
    "    avg_time = total_time / num_trials\n",
    "    avg_power = total_power / num_trials\n",
    "    avg_energy = avg_time * avg_power\n",
    "    print(f\"Avg Inference Time: {avg_time:.4f} sec\")\n",
    "    print(f\"Avg Power: {avg_power:.4f} W\")\n",
    "    print(f\"Avg Energy: {avg_energy:.4f} J\")\n",
    "\n",
    "# # Replace this with your actual inference method\n",
    "# def run():\n",
    "#     # Example workload (simulate inference)\n",
    "#     import torch\n",
    "#     x = torch.randn(1, 3, 224, 224).cuda()\n",
    "#     model = torch.nn.Conv2d(3, 64, kernel_size=3, padding=1).cuda()\n",
    "#     with torch.no_grad():\n",
    "#         for _ in range(100):\n",
    "#             y = model(x)\n",
    "\n",
    "# Run the test\n",
    "run_inference_with_metrics(run, num_trials=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size 78.12292861938477, gpu memory 106.69287109375, cpu mem 1043.9609375\n",
      "SNN-based RepNet parameters: 20.48M\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    # Total number of parameters in the model\n",
    "    return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "def get_model_size(model):\n",
    "    \"\"\"Return model size in MB.\"\"\"\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    return param_size / (1024 ** 2)\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"Return GPU memory usage in MB.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    return 0.0\n",
    "\n",
    "def get_cpu_memory():\n",
    "    \"\"\"Return RAM usage in MB.\"\"\"\n",
    "    return psutil.Process(os.getpid()).memory_info().rss / (1024 ** 2)\n",
    "\n",
    "print(f\"model size {get_model_size(model)}, gpu memory {get_gpu_memory()}, cpu mem {get_cpu_memory()}\")\n",
    "print(f\"SNN-based RepNet parameters: {count_parameters(model) / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_period_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate video with counts\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rep_frames \u001b[38;5;241m=\u001b[39m plots\u001b[38;5;241m.\u001b[39mplot_repetitions(raw_frames[:\u001b[38;5;28mlen\u001b[39m(\u001b[43mbest_period_count\u001b[49m)], best_period_count\u001b[38;5;241m.\u001b[39mtolist(), best_periodicity_score\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m video \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoWriter(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(OUT_VISUALIZATIONS_DIR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepetitions.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mVideoWriter_fourcc(\u001b[38;5;241m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmp4v\u001b[39m\u001b[38;5;124m'\u001b[39m), fps, rep_frames[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;129;01min\u001b[39;00m rep_frames:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_period_count' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate video with counts\n",
    "rep_frames = plots.plot_repetitions(raw_frames[:len(best_period_count)], best_period_count.tolist(), best_periodicity_score.tolist() if not True else None)\n",
    "video = cv2.VideoWriter(os.path.join(OUT_VISUALIZATIONS_DIR, 'repetitions.mp4'), cv2.VideoWriter_fourcc(*'mp4v'), fps, rep_frames[0].shape[:2][::-1])\n",
    "for frame in rep_frames:\n",
    "    video.write(frame)\n",
    "video.release()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(best_period_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 256)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_frames), len(best_period_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_period_count.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_period_count.tolist()[-1]\n",
    "round(best_period_count.tolist()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_data[\"count\"] = round(best_period_count.tolist()[-1])\n",
    "try:\n",
    "    if (out_df.loc[(out_df['class'] == event_class) & (out_df['condition'] == event_user), 'count']):\n",
    "        out_df.loc[(out_df['class'] == event_class) & (out_df['condition'] == event_user), 'count'] = count_data[\"count\"]\n",
    "except:\n",
    "    out_df = pd.concat([out_df, pd.DataFrame([count_data])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(out_csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>condition</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class2</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>class3</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>class4</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>class6</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_fluorescent</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_lab</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>class7</td>\n",
       "      <td>user02_natural</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>class5</td>\n",
       "      <td>user02_fluorescent_led</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class               condition  count\n",
       "0   class2  user02_fluorescent_led     10\n",
       "1   class2      user02_fluorescent     14\n",
       "2   class2              user02_lab      9\n",
       "3   class2              user02_led      9\n",
       "4   class2          user02_natural     16\n",
       "5   class3  user02_fluorescent_led     12\n",
       "6   class3      user02_fluorescent     11\n",
       "7   class3              user02_lab     10\n",
       "8   class3              user02_led     12\n",
       "9   class3          user02_natural     11\n",
       "10  class4  user02_fluorescent_led      8\n",
       "11  class4      user02_fluorescent      9\n",
       "12  class4              user02_lab      9\n",
       "13  class4              user02_led      7\n",
       "14  class4          user02_natural     10\n",
       "15  class5  user02_fluorescent_led      6\n",
       "16  class5      user02_fluorescent      9\n",
       "17  class5              user02_lab      8\n",
       "18  class5              user02_led      6\n",
       "19  class5          user02_natural      8\n",
       "20  class6  user02_fluorescent_led      6\n",
       "21  class6      user02_fluorescent      9\n",
       "22  class6              user02_lab      9\n",
       "23  class6              user02_led      9\n",
       "24  class6          user02_natural      8\n",
       "25  class7  user02_fluorescent_led      7\n",
       "26  class7      user02_fluorescent      5\n",
       "27  class7              user02_lab      9\n",
       "28  class7              user02_led      6\n",
       "29  class7          user02_natural      8\n",
       "30  class5  user02_fluorescent_led      4\n",
       "31  class5  user02_fluorescent_led      6\n",
       "0   class5  user02_fluorescent_led      6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df\n",
    "# out_df.loc[(out_df['class'] == event_class) & (out_df['condition'] == event_user), 'count'] = count_data[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage: 106.76 MB\n",
      "CPU RAM Usage: 1406.93 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import psutil\n",
    "\n",
    "# GPU Memory Usage\n",
    "gpu_memory = torch.cuda.memory_allocated() / (1024 * 1024)  # Convert to MB\n",
    "print(f\"GPU Memory Usage: {gpu_memory:.2f} MB\")\n",
    "\n",
    "# CPU RAM Usage\n",
    "ram_usage = psutil.Process().memory_info().rss / (1024 * 1024)  # Convert to MB\n",
    "print(f\"CPU RAM Usage: {ram_usage:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
